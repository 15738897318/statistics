<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Statistics: ClassificationKNN</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" integrity="sha512-1ycn6IcaQQ40/MKBW2W4Rhis/DbILU74C1vSrLJxCq57o941Ym01SwNsOMqvEBFlcgUa6xLiPY/NS5R+E6ztJQ==" crossorigin="anonymous" referrerpolicy="no-referrer">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js" integrity="sha384-U1DAWAznBHeqEIlVSCgzq+c9gqGAJn5c/t99JyeKa9xxaYpSvHU5awsuZVVFIhvj" crossorigin="anonymous"></script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>
    <style>
    var {
      font-style: italics;
      font-weight: bold;
    }
    td {
      vertical-align: top;
    }
    </style>
  </head>
  <body>
    <div class="bg-dark">
      <div class="container-xl">
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
          <div class="container-fluid">
            <a class="navbar-brand" href=index.html>
              <img src="assets/statistics.png" alt="statistics" class="d-inline-block align-top" width="25" height="25">
              Statistics
            </a>
            <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav">
                <li class="nav-item">
                  <a class="nav-link" href="index.html#Classification Classes">
                    <i class="fas fa-list-alt"></i>
                    Classification Classes
                  </a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="https://gnu-octave.github.io/packages/">
                  <img src="assets/octave-logo.svg" alt="GNU Octave logo" class="d-inline-block align-top" width="25" height="25">
                    Octave Packages
                  </a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="https://www.octave.org">
                    <i class="fas fa-home"></i>
                    GNU Octave website
                  </a>
                </li>
              </ul>
            </div>
          </div>
        </nav>
      </div>
    </div>
    <div class="container-xl my-4">
      <div class="card rounded">
        <div class="card-header card-header-mod">
          <div class="row d-flex flex-wrap align-items-center">
            <div class="col-sm-3 col-md-5 mb-2 mb-sm-0">
              <h3 class="d-inline-block mr-2">
              Class&nbsp;Definition: <b><code>ClassificationKNN</code></b>
              </h3>
            </div>
          </div>
        </div>
        <div class="card-body">
<dl>
<dt><u>statistics:</u> <var>obj</var> = <b>ClassificationKNN</b><i> (<var>X</var>, <var>Y</var>)</i></dt>
<dt><u>statistics:</u> <var>obj</var> = <b>ClassificationKNN</b><i> (&hellip;, <var>name</var>, <var>value</var>)</i></dt>
</dl>

<p> Create a <code>ClassificationKNN</code> class object containing a k-Nearest
 Neighbor classification model.
</p>
<div class="ms-5">
<p> <code><var>obj</var> = ClassificationKNN (<var>X</var>, <var>Y</var>)</code> returns a
 ClassificationKNN object, with <var>X</var> as the predictor data and <var>Y</var>
 containing the class labels of observations in <var>X</var>.
</p>
 <ul>
<li>
 <code>X</code> must be a <math>N&times;P</math> numeric matrix of input data where rows
 correspond to observations and columns correspond to features or variables.
 <var>X</var> will be used to train the kNN model.
 </li><li>
 <code>Y</code> is <math>N&times;1</math> matrix or cell matrix containing the class labels of
 corresponding predictor data in <var>X</var>. <var>Y</var> can contain any type of
 categorical data. <var>Y</var> must have same numbers of Rows as <var>X</var>.
 </li></ul>

<p> <code><var>obj</var> = ClassificationKNN (&hellip;, <var>name</var>, <var>value</var>)</code>
 returns a ClassificationKNN object with parameters specified by
 <code>Name-Value</code> pair arguments.  Type <code>help fitcknn</code> for more info.
</p>
<p> A <code>ClassificationKNN</code> object, <var>obj</var>, stores the labelled training
 data and various parameters for the k-Nearest Neighbor classification model,
 which can be accessed in the following fields:
</p>
 <table>
<thead><tr><th width="28%"><var>Field</var></th><th width="2%"></th><th width="70%"><var>Description</var></th></tr></thead>
<tr><td width="28%"><code>obj.X</code></td><td width="2%"></td><td width="70%">Unstandardized predictor data, specified as a
 numeric matrix.  Each column of <var>X</var> represents one predictor (variable),
 and each row represents one observation.</td></tr>
<tr><td width="28%"><code>obj.Y</code></td><td width="2%"></td><td width="70%">Class labels, specified as a logical or
 numeric vector, or cell array of character vectors.  Each value in <var>Y</var> is
 the observed class label for the corresponding row in <var>X</var>.</td></tr>
<tr><td width="28%"><code>obj.NumObservations</code></td><td width="2%"></td><td width="70%">Number of observations used in
 training the ClassificationKNN model, specified as a positive integer scalar.
 This number can be less than the number of rows in the training data because
 rows containing <code>NaN</code> values are not part of the fit.</td></tr>
<tr><td width="28%"><code>obj.RowsUsed</code></td><td width="2%"></td><td width="70%">Rows of the original training data
 used in fitting the ClassificationKNN model, specified as a numerical vector.
 If you want to use this vector for indexing the training data in <var>X</var>, you
 have to convert it to a logical vector, i.e
 <code>X = obj.X(logical (obj.RowsUsed), :);</code></td></tr>
<tr><td width="28%"><code>obj.Standardize</code></td><td width="2%"></td><td width="70%">A boolean flag indicating whether
 the data in <var>X</var> have been standardized prior to training.</td></tr>
<tr><td width="28%"><code>obj.Sigma</code></td><td width="2%"></td><td width="70%">Predictor standard deviations, specified
 as a numeric vector of the same length as the columns in <var>X</var>.  If the
 predictor variables have not been standardized, then <code>&quot;obj.Sigma&quot;</code> is
 empty.</td></tr>
<tr><td width="28%"><code>obj.Mu</code></td><td width="2%"></td><td width="70%">Predictor means, specified as a numeric
 vector of the same length as the columns in <var>X</var>.  If the predictor
 variables have not been standardized, then <code>&quot;obj.Mu&quot;</code> is empty.</td></tr>
<tr><td width="28%"><code>obj.NumPredictors</code></td><td width="2%"></td><td width="70%">The number of predictors
 (variables) in <var>X</var>.</td></tr>
<tr><td width="28%"><code>obj.PredictorNames</code></td><td width="2%"></td><td width="70%">Predictor variable names,
 specified as a cell array of character vectors.  The variable names are in
 the same order in which they appear in the training data <var>X</var>.</td></tr>
<tr><td width="28%"><code>obj.ResponseName</code></td><td width="2%"></td><td width="70%">Response variable name, specified
 as a character vector.</td></tr>
<tr><td width="28%"><code>obj.ClassNames</code></td><td width="2%"></td><td width="70%">Names of the classes in the training
 data <var>Y</var> with duplicates removed, specified as a cell array of character
 vectors.</td></tr>
<tr><td width="28%"><code>obj.BreakTies</code></td><td width="2%"></td><td width="70%">Tie-breaking algorithm used by predict
 when multiple classes have the same smallest cost, specified as one of the
 following character arrays: <code>&quot;smallest&quot;</code> (default), which favors the
 class with the smallest index among the tied groups, i.e. the one that
 appears first in the training labelled data.  <code>&quot;nearest&quot;</code>, which favors
 the class with the nearest neighbor among the tied groups, i.e. the class
 with the closest member point according to the distance metric used.
 <code>&quot;nearest&quot;</code>, which randomly picks one class among the tied groups.</td></tr>
<tr><td width="28%"><code>obj.Prior</code></td><td width="2%"></td><td width="70%">Prior probabilities for each class,
 specified as a numeric vector.  The order of the elements in <code>Prior</code>
 corresponds to the order of the classes in <code>ClassNames</code>.</td></tr>
<tr><td width="28%"><code>obj.Cost</code></td><td width="2%"></td><td width="70%">Cost of the misclassification of a point,
 specified as a square matrix. <code>Cost(i,j)</code> is the cost of classifying a
 point into class <code>j</code> if its true class is <code>i</code> (that is, the rows
 correspond to the true class and the columns correspond to the predicted
 class).  The order of the rows and columns in <code>Cost</code> corresponds to the
 order of the classes in <code>ClassNames</code>.  The number of rows and columns
 in <code>Cost</code> is the number of unique classes in the response.  By default,
 <code>Cost(i,j) = 1</code> if <code>i != j</code>, and <code>Cost(i,j) = 0</code> if
 <code>i = j</code>.  In other words, the cost is 0 for correct classification and
 1 for incorrect classification.</td></tr>
<tr><td width="28%"><code>obj.NumNeighbors</code></td><td width="2%"></td><td width="70%">Number of nearest neighbors in
 <var>X</var> used to classify each point during prediction, specified as a
 positive integer value.</td></tr>
<tr><td width="28%"><code>obj.Distance</code></td><td width="2%"></td><td width="70%">Distance metric, specified as a
 character vector.  The allowable distance metric names depend on the choice
 of the neighbor-searcher method.  See the available distance metrics in
 <code>knnseaarch</code> for more info.</td></tr>
<tr><td width="28%"><code>obj.DistanceWeight</code></td><td width="2%"></td><td width="70%">Distance weighting function,
 specified as a function handle, which accepts a matrix of nonnegative
 distances, and returns a matrix the same size containing nonnegative distance
 weights.</td></tr>
<tr><td width="28%"><code>obj.DistParameter</code></td><td width="2%"></td><td width="70%">Parameter for the distance
 metric, specified either as a positive definite covariance matrix (when the
 distance metric is <code>&quot;mahalanobis&quot;</code>, or a positive scalar as the
 Minkowski distance exponent (when the distance metric is <code>&quot;minkowski&quot;</code>,
 or a vector of positive scale values with length equal to the number of
 columns of <var>X</var> (when the distance metric is <code>&quot;seuclidean&quot;</code>.  For
 any other distance metric, the value of <code>DistParameter</code> is empty.</td></tr>
<tr><td width="28%"><code>obj.NSMethod</code></td><td width="2%"></td><td width="70%">Nearest neighbor search method,
 specified as either <code>&quot;kdtree&quot;</code>, which creates and uses a Kd-tree to
 find nearest neighbors, or <code>&quot;exhaustive&quot;</code>, which uses the exhaustive
 search algorithm by computing the distance values from all points in <var>X</var>
 to find nearest neighbors.</td></tr>
<tr><td width="28%"><code>obj.IncludeTies</code></td><td width="2%"></td><td width="70%">A boolean flag indicating whether
 prediction includes all the neighbors whose distance values are equal to the
 <math>k^th</math> smallest distance.  If <code>IncludeTies</code> is <code>true</code>,
 prediction includes all of these neighbors.  Otherwise, prediction uses
 exactly <math>k</math> neighbors.</td></tr>
<tr><td width="28%"><code>obj.BucketSize</code></td><td width="2%"></td><td width="70%">Maximum number of data points in the
 leaf node of the Kd-tree, specified as positive integer value. This argument
 is meaningful only when <code>NSMethod</code> is <code>&quot;kdtree&quot;</code>.</td></tr>
</table>

<p> <strong>See also: </strong>
  <a href="fitcknn.html">fitcknn</a>, 
  <a href="knnsearch.html">knnsearch</a>, 
  <a href="rangesearch.html">rangesearch</a>, 
  <a href="pdist2.html">pdist2</a>
</p>
</div>
        <div class="container-xl my-4">
          <div class="card rounded">
            <div class="card-header card-header-mod">
              <div class="row d-flex flex-wrap align-items-center">
                <div class="col-sm-3 col-md-5 mb-2 mb-sm-0">
                  <h3 class="d-inline-block mr-2">
                  Method: <b><code>predict</code></b>
                  </h3>
                </div>
              </div>
            </div>
            <div class="card-body">
<dl>
<dt><u>ClassificationKNN:</u> <var>label</var> = <b>predict</b><i> (<var>obj</var>, <var>XC</var>)</i></dt>
<dt><u>ClassificationKNN:</u> [<var>label</var>, <var>score</var>, <var>cost</var>] = <b>predict</b><i> (<var>obj</var>, <var>XC</var>)</i></dt>
</dl>

<p> Classify new data points into categories using the kNN algorithm from a
 k-Nearest Neighbor classification model.
</p>
<div class="ms-5">
<p> <code><var>label</var> = predict (<var>obj</var>, <var>XC</var>)</code> returns the matrix of
 labels predicted for the corresponding instances in <var>XC</var>, using the
 predictor data in <code>obj.X</code> and corresponding labels, <code>obj.Y</code>,
 stored in the k-Nearest Neighbor classification model, <var>obj</var>.
</p>
<p> <var>XC</var> must be an <math>M&times;P</math> numeric matrix with the same number of
 features <math>P</math> as the corresponding predictors of the kNN model in
 <var>obj</var>.
</p>
<p> <code>[<var>label</var>, <var>score</var>, <var>cost</var>] = predict (<var>obj</var>, <var>XC</var>)</code>
 also returns <var>score</var>, which contains the predicted class scores or
 posterior probabilities for each instance of the corresponding unique
 classes, and <var>cost</var>, which is a matrix containing the expected cost
 of the classifications.
</p>
<p> <strong>See also: </strong>
  <a href="fitcknn.html">fitcknn</a>, 
  <a href="ClassificationKNN.html">ClassificationKNN</a>
</p>
</div>
            </div>
          </div>
        </div>

        <div class="container-xl my-4">
          <div class="card rounded">
            <div class="card-header card-header-mod">
              <div class="row d-flex flex-wrap align-items-center">
                <div class="col-sm-3 col-md-5 mb-2 mb-sm-0">
                  <h3 class="d-inline-block mr-2">
                  Example: 1
                  </h3>
                </div>
              </div>
            </div>
            <div class="card-body">
              <div class="container bg-light">
                <div class="row">
                  <table><tbody><tr>
                    <td>&nbsp;</td>
                    <td><pre class="example">

 ## Create a k-nearest neighbor classifier for Fisher's iris data with k = 5.
 ## Evaluate some model predictions on new data.

 load fisheriris
 x = meas;
 y = species;
 xc = [min(x); mean(x); max(x)];
 obj = fitcknn (x, y, "NumNeighbors", 5, "Standardize", 1);
 [label, score, cost] = predict (obj, xc)

label =
{
  [1,1] = versicolor
  [2,1] = versicolor
  [3,1] = virginica
}

score =

   0.4000   0.6000        0
        0   1.0000        0
        0        0   1.0000

cost =

   0.6000   0.4000   1.0000
   1.0000        0   1.0000
   1.0000   1.0000        0

                    </pre></td></tr></tbody>
                  </table>

                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="container-xl my-4">
          <div class="card rounded">
            <div class="card-header card-header-mod">
              <div class="row d-flex flex-wrap align-items-center">
                <div class="col-sm-3 col-md-5 mb-2 mb-sm-0">
                  <h3 class="d-inline-block mr-2">
                  Example: 2
                  </h3>
                </div>
              </div>
            </div>
            <div class="card-body">
              <div class="container bg-light">
                <div class="row">
                  <table><tbody><tr>
                    <td>&nbsp;</td>
                    <td><pre class="example">

 ## Train a k-nearest neighbor classifier for k = 10
 ## and plot the decision boundaries.

 load fisheriris
 idx = ! strcmp (species, "setosa");
 X = meas(idx,3:4);
 Y = cast (strcmpi (species(idx), "virginica"), "double");
 obj = fitcknn (X, Y, "Standardize", 1, "NumNeighbors", 10, "NSMethod", "exhaustive")
 x1 = [min(X(:,1)):0.03:max(X(:,1))];
 x2 = [min(X(:,2)):0.02:max(X(:,2))];
 [x1G, x2G] = meshgrid (x1, x2);
 XGrid = [x1G(:), x2G(:)];
 pred = predict (obj, XGrid);
 gidx = logical (str2num (cell2mat (pred)));

 figure
 scatter (XGrid(gidx,1), XGrid(gidx,2), "markerfacecolor", "magenta");
 hold on
 scatter (XGrid(!gidx,1), XGrid(!gidx,2), "markerfacecolor", "red");
 plot (X(Y == 0, 1), X(Y == 0, 2), "ko", X(Y == 1, 1), X(Y == 1, 2), "kx");
 xlabel ("Petal length (cm)");
 ylabel ("Petal width (cm)");
 title ("5-Nearest Neighbor Classifier Decision Boundary");
 legend ({"Versicolor Region", "Virginica Region", ...
         "Sampled Versicolor", "Sampled Virginica"}, ...
         "location", "northwest")
 axis tight
 hold off

obj =

  ClassificationKNN object with properties:

            BreakTies: smallest
           BucketSize: [1x1 double]
           ClassNames: [2x1 cell]
                 Cost: [2x2 double]
        DistParameter: [0x0 double]
             Distance: euclidean
       DistanceWeight: [1x1 function_handle]
          IncludeTies: 0
                   Mu: [1x2 double]
             NSMethod: exhaustive
         NumNeighbors: [1x1 double]
      NumObservations: [1x1 double]
        NumPredictors: [1x1 double]
       PredictorNames: [1x2 cell]
                Prior: [2x1 double]
         ResponseName: Y
             RowsUsed: [100x1 double]
                Sigma: [1x2 double]
          Standardize: 1
                    X: [100x2 double]
                    Y: [100x1 double]

                    </pre></td></tr></tbody>
                  </table>
                  <div class="text-center">
                    <img src="assets/ClassificationKNN_201.png" class="rounded img-thumbnail" alt="plotted figure">
                  </div><p></p>

                </div>
              </div>
            </div>
          </div>
        </div>


        </div>
      </div>
    </div>

  </body>
</html>
